# MeCab + pandas + wordcloudã®å‡¦ç†

import MeCab
import pandas as pd
from wordcloud import WordCloud
import os
from datetime import datetime
import numpy as np
from PIL import Image
import discord
from dotenv import load_dotenv
from collections import Counter
import emoji
import unicodedata
import asyncio

# Lambda/ãƒ­ãƒ¼ã‚«ãƒ«ä¸¡å¯¾å¿œã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from app.get_data import get_db_connection
except ImportError:
    from get_data import get_db_connection

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ï¼‰
load_dotenv()

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã¨ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’å–å¾—
DISCORD_BOT_TOKEN = os.getenv('DISCORD_BOT_TOKEN')
DISCORD_CHANNEL_ID = int(os.getenv('DISCORD_CHANNEL_ID')) if os.getenv('DISCORD_CHANNEL_ID') else None

# MeCab Taggerã®åˆæœŸåŒ–
mecab = MeCab.Tagger()

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‚’å–å¾—ã—ã¦ãƒªã‚¹ãƒˆã«å…¥ã‚Œã‚‹
def get_messages(conn):
    if not conn:
        return []
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT content FROM messages WHERE content IS NOT NULL AND content != '' AND DATE_TRUNC('month', created_at) = DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month');")
            rows = cur.fetchall()
            return [row[0] for row in rows if row[0].strip()]  # ç©ºã§ãªã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã¿
    except Exception as e:
        print(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []
    finally:
        if conn:
            conn.close()
            print("\nğŸ˜ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é–‰ã˜ã¾ã—ãŸã€‚")

# çµµæ–‡å­—ã¨ç©ºç™½ã‚’é™¤ã„ãŸãƒ†ã‚­ã‚¹ãƒˆã®ã¿æŠ½å‡º
def separate_text(messages):
    text_list = []

    for sentence in messages:
        texts = []
        for char in sentence:
            if emoji.is_emoji(char):
                continue
            if unicodedata.category(char).startswith(("P", "S")):
                continue
            if char.isdigit() and len(char) == 1:
                continue
            if not char.isspace():  # ç©ºç™½æ–‡å­—ã¯ç„¡è¦–
                texts.append(char)

        text_list.append("".join(texts))

    return text_list

def analyze_messages(messages):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å½¢æ…‹ç´ è§£æã—ã¦å˜èªã®é »åº¦ã‚’è¨ˆç®—"""
    data = []
    text_list = separate_text(messages)

    for sentence in text_list:
        words, roots, parts = [], [], []
        node = mecab.parseToNode(sentence)
        while node:
            surface = node.surface
            features = node.feature.split(",")
            base = features[6] if len(features) > 6 else "*"
            if base == "*" or not base.strip():
                base = surface
            pos = features[0]
            if surface:
                words.append(surface)
                roots.append(base)
                parts.append(pos)
            node = node.next
        data.append({"sentence": sentence, "words": words, "root": roots, "part": parts})

    df = pd.DataFrame(data)

    # æ„å‘³ã®ã‚ã‚‹å˜èªã‚’æŠ½å‡º
    filtered_words = []
    STOP_WORDS = {"ã®", "ãã†", "ãªã„", "ã„ã„", "ã‚“", "ã¨ã", "ã‚ˆã†", "ã“ã‚Œ", "ã“ã¨","äºº","ä»Š","æ™‚","æ„Ÿã˜","çš„","ä½•","ãªã«","ãªã‚“","åŒ–","ä»–","HTTPS"}

    for _, row in df.iterrows():
        for root, part in zip(row["root"], row["part"]):
            if part in ["å½¢å®¹è©", "å½¢å®¹å‹•è©", "åè©", "æ„Ÿå‹•è©"] and root not in STOP_WORDS and len(root) != 1 and root.strip():
                filtered_words.append(root)

    return Counter(filtered_words)

def create_wordcloud(frequencies):
    """ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”»åƒã‚’ç”Ÿæˆ"""
    OUTPUT_DIR = os.getenv("OUTPUT_DIR", "/tmp/output")
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # Lambda/ãƒ­ãƒ¼ã‚«ãƒ«ä¸¡å¯¾å¿œã®ãƒ­ã‚´ãƒ‘ã‚¹
    logo_paths = [
        "/var/task/app/logo/PeachTech_black.png",  # Lambdaç’°å¢ƒ
        "app/logo/PeachTech_black.png",             # ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰å®Ÿè¡Œï¼‰
        "logo/PeachTech_black.png",                 # ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆappãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å®Ÿè¡Œï¼‰
    ]

    logo_path = None
    for path in logo_paths:
        if os.path.exists(path):
            logo_path = path
            break

    if not logo_path:
        raise FileNotFoundError("ãƒ­ã‚´ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    mask_image = np.array(Image.open(logo_path))

    wordcloud = WordCloud(
        font_path="/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
        background_color="white",
        mask=mask_image,
        colormap="tab10",
        width=800,
        height=800
    ).generate_from_frequencies(frequencies)

    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    output_filename = f"wordcloud_output_{timestamp}.png"
    output_path = os.path.join(OUTPUT_DIR, output_filename)
    wordcloud.to_file(output_path)
    print(f"âœ… WordCloudç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ â†’ {output_path}")
    return output_path

async def send_discord_message(word_frequencies):
    """Discordã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ç”»åƒã‚’é€ä¿¡"""
    intents = discord.Intents.default()
    client = discord.Client(intents=intents)

    @client.event
    async def on_ready():
        print(f'{client.user} ã¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã—ãŸã€‚')

        try:
            top_words = word_frequencies.most_common(3)

            rank_strings = []
            for rank, (word, count) in enumerate(top_words, 1):
                crown = "ğŸ‘‘ " if rank == 1 else ""
                rank_strings.append(f"{crown}{rank} ä½  ã€Œ**{word}**ã€  {count}å›")

            last_month = (datetime.now().month - 1) or 12
            last_month_year = (datetime.now().year - 1) if last_month == 12 else datetime.now().year
            ranking_text = "\n".join(rank_strings)
            final_message = f"ğŸ‘{last_month_year}å¹´{last_month}æœˆã®ã´ã¡ã¦ããƒˆãƒ¬ãƒ³ãƒ‰ãƒ¯ãƒ¼ãƒ‰ã¯â€¦ğŸ—£ï¸\n## {ranking_text}\n\nã§ã—ãŸï¼"

            image_path = create_wordcloud(word_frequencies)
            channel = client.get_channel(DISCORD_CHANNEL_ID)

            if channel:
                await channel.send(
                    final_message,
                    file=discord.File(image_path)
                )
                print(f"ãƒãƒ£ãƒ³ãƒãƒ« '{channel.name}' ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ç”»åƒã‚’æŠ•ç¨¿ã—ã¾ã—ãŸã€‚")
            else:
                print(f"ã‚¨ãƒ©ãƒ¼: ãƒãƒ£ãƒ³ãƒãƒ«ID {DISCORD_CHANNEL_ID} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise

        finally:
            await client.close()

    await client.start(DISCORD_BOT_TOKEN)

def run_ranking_bot():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆã¨DiscordæŠ•ç¨¿"""
    print("ğŸ‘ ãƒ©ãƒ³ã‚­ãƒ³ã‚°Botã‚’é–‹å§‹ã—ã¾ã™...")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    connection = get_db_connection()
    if not connection:
        raise Exception("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾—
    messages = get_messages(connection)
    if not messages:
        raise Exception("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

    print(f"ğŸ“Š {len(messages)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ã—ã¾ã—ãŸ")

    # å½¢æ…‹ç´ è§£æ
    word_frequencies = analyze_messages(messages)
    print(f"ğŸ“ {len(word_frequencies)}å€‹ã®å˜èªã‚’è§£æã—ã¾ã—ãŸ")

    # DiscordæŠ•ç¨¿
    asyncio.run(send_discord_message(word_frequencies))

# Lambdaç”¨ãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–¢æ•°
def lambda_handler(event, context):
    """AWS Lambdaç”¨ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼é–¢æ•°"""
    try:
        run_ranking_bot()
        return {
            'statusCode': 200,
            'body': 'ãƒ©ãƒ³ã‚­ãƒ³ã‚°Botã®å®Ÿè¡ŒãŒå®Œäº†ã—ã¾ã—ãŸ'
        }
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            'statusCode': 500,
            'body': f'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}'
        }

# ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç”¨
if __name__ == '__main__':
    if not DISCORD_BOT_TOKEN or not DISCORD_CHANNEL_ID:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° DISCORD_BOT_TOKEN ã¾ãŸã¯ DISCORD_CHANNEL_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        exit(1)

    run_ranking_bot()